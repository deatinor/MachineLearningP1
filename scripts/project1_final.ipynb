{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import datetime\n",
    "from helpers import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../../train.csv' # TODO: download train data and supply path here \n",
    "y_starting, tX_starting, ids = load_csv_data(DATA_TRAIN_PATH,sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=y_starting.copy()\n",
    "tX=tX_starting.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic functions implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the testing of the implementation of the 6 functions we did not preprocess the dataset.\n",
    "The aim of this part is just to show that they work correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tX,tX_test,y,y_test=split_data(tX,y,0.5)\n",
    "print(tX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w,loss=least_squares(y,tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate(y,tX,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic least square method achieve a 74% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lamb=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w,loss=ridge_regression(y,tX,lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate(y,tX,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy slightly decreases using the ridge regression. It was expected. The problem in the standard case is well posed, so the ridge regression is not convenient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_w=np.zeros(tX.shape[1])\n",
    "gamma=0.0000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w,loss=least_squares_GD(y,tX,initial_w,10000,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate(y,tX,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with a lot of iterations the gradient descent is not able to match the results obtained with the least squares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_w=np.zeros(tX.shape[1])\n",
    "gamma=0.00000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w,loss=least_squares_SGD(y,tX,initial_w,100000,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate(y,tX,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent is not able to achieve a better result than least square.\n",
    "The fastest iteration step time allows for more iterations than the standard GD.\n",
    "It is however necessary a lower step size to keep the method stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_log=y.copy()\n",
    "y_log[y_log==-1]=0\n",
    "y_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_w=np.zeros(tX.shape[1])\n",
    "gamma=0.00000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w,loss=logistic_regression(y_log,tX,initial_w,10000,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate(y,tX,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0., ...,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_log=y.copy()\n",
    "y_log[y_log==-1]=0\n",
    "y_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_w=np.zeros(tX.shape[1])\n",
    "gamma=0.00000000001\n",
    "lamb=1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w,loss=reg_logistic_regression(y_log,tX,lamb,initial_w,1,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67690800000000007"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(y,tX,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are quite similar to the standard logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Logistic Regression Newton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0., ...,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_log=y.copy()\n",
    "y_log[y_log==-1]=0\n",
    "y_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.21111111e-05"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_w=np.zeros(tX.shape[1])\n",
    "gamma=0.00000000001\n",
    "lamb=1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w,loss=reg_logistic_regression_newton(y_log,tX,lamb,initial_w,100,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83310799999999996"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(y,tX,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results improved over the standard logistic regression. \n",
    "Few iterations are necessary to achieve a good result compared to the previous methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete columns with low correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def drop_col(tX_starting):\n",
    "    drop_columns=[]\n",
    "    #for i in range(tX_starting.shape[1]):\n",
    "    #    coeff=np.corrcoef(y,tX_starting[:,i])[0,1]\n",
    "    #    if abs(coeff)<0.000:\n",
    "    #        drop_columns.append(i)\n",
    "\n",
    "\n",
    "    tX=np.delete(tX_starting,drop_columns,axis=1)\n",
    "    return tX\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replace_nan(tX_starting,median=False):\n",
    "    tX=tX_starting.copy()\n",
    "    nan_position=[tX[:,[0,4,23]]!=-999][0]*1\n",
    "\n",
    "    for col in range(tX.shape[1]):\n",
    "        column=tX[:,col][tX[:,col]!=-999]\n",
    "        if median==False:\n",
    "            mean=column.mean()\n",
    "            median=np.median(column)\n",
    "\n",
    "        tX[:,col][tX[:,col]==-999]=median    \n",
    "    \n",
    "    return nan_position,tX,median\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def categorical_variables(tX_starting):\n",
    "    tX=tX_starting.copy()\n",
    "    \n",
    "    cat_variable=22\n",
    "    values=[0,1,2]\n",
    "\n",
    "    added_matrix=np.zeros([tX.shape[0],3])\n",
    "    added_matrix[:,0]=np.array([tX[:,22]==0])\n",
    "    added_matrix[:,1]=np.array([tX[:,22]==1])\n",
    "    added_matrix[:,2]=np.array([tX[:,22]==2])\n",
    "    \n",
    "    tX=np.delete(tX,[22],axis=1)\n",
    "    \n",
    "    return added_matrix,tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def before_poly(tX_starting,median=False):\n",
    "    tX=drop_col(tX_starting)\n",
    "    nan_position,tX,median=replace_nan(tX,median)\n",
    "    #added_matrix,tX=categorical_variables(tX)\n",
    "    #full_added_matrix=np.concatenate((added_matrix,nan_position),axis=1)\n",
    "    return nan_position,tX,median\n",
    "    return full_added_matrix,tX,median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_poly(tX,degree,y,prod_to_exclude=False,train=True,columns_to_consider=False,exponential=False,cross_products=False,added_matrix_for_cross=False,threshold_power=0.0,threshold_cross=0.00,exclude=False):\n",
    "    if not columns_to_consider:\n",
    "        columns_to_consider=range(tX.shape[1])\n",
    "    if not prod_to_exclude:\n",
    "        prod_to_exclude=[]\n",
    "    if exclude==False:\n",
    "        exclude=[]\n",
    "    dict_cross={}\n",
    "    \n",
    "    columns_to_consider=[x for x in columns_to_consider if x not in exclude]\n",
    "    columns_to_consider=np.array(columns_to_consider)\n",
    "    # Add power of the matrix\n",
    "    final_list=[]\n",
    "    for i in range(2,degree+1):\n",
    "        #corr=np.corrcoef(tX[:,columns_to_consider]**i,y,rowvar=0)[:-1,-1]\n",
    "        #cols=abs(corr)>threshold_power\n",
    "        #cols=columns_to_consider[cols]\n",
    "        cols=columns_to_consider\n",
    "        tX=np.concatenate((tX,tX[:,cols]**i),axis=1)\n",
    "    for i in range(2,18):\n",
    "        if i%2==1:\n",
    "            tX=np.concatenate((tX,np.sqrt(abs(tX[:,cols]**i))),axis=1)\n",
    "    if exponential:\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/100)),axis=1)\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/80)),axis=1)\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/60)),axis=1)\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/50)),axis=1)\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/40)),axis=1)\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/20)),axis=1)\n",
    "#         tX=np.concatenate((tX,tX[:,cols]**(1.0/5)),axis=1)\n",
    "#         tX=np.concatenate((tX,tX[:,cols]**(1.0/7)),axis=1)\n",
    "\n",
    "    if cross_products:\n",
    "        if added_matrix_for_cross.any():\n",
    "            # Add to columns to consider\n",
    "            for i in range(tX.shape[1],tX.shape[1]+added_matrix_for_cross.shape[1]):\n",
    "                columns_to_consider=np.append(columns_to_consider,i)\n",
    "            # Concatenate\n",
    "            tX=np.concatenate((tX,added_matrix_for_cross),axis=1)\n",
    "            final_list.append(tX)\n",
    "        start_cross=tX.shape[1]\n",
    "        for i,col1 in enumerate(columns_to_consider):\n",
    "            for j,col2 in enumerate(columns_to_consider):\n",
    "                if j>i and (i,j) not in prod_to_exclude:\n",
    "                    if train:\n",
    "                        prod=tX[:,col1]*tX[:,col2]\n",
    "                        corr=np.corrcoef(prod,y)[0,1]\n",
    "                        if abs(corr)>threshold_cross:\n",
    "                            final_list.append(prod.reshape([prod.shape[0],1]))\n",
    "\n",
    "                            #print(start_cross,type(start_cross))\n",
    "                            dict_cross[start_cross]=tuple([i,j])\n",
    "                            start_cross+=1\n",
    "                        else:\n",
    "                            prod_to_exclude.append((i,j))\n",
    "                    else:\n",
    "                        prod=tX[:,col1]*tX[:,col2]\n",
    "                        final_list.append(prod.reshape([prod.shape[0],1]))\n",
    "        final_tuple=tuple(final_list)\n",
    "        tX=np.concatenate(final_tuple,axis=1)\n",
    "    return tX,prod_to_exclude,dict_cross\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(tX,mean=False,std=False,train=False):# Normalizing\n",
    "    if train:\n",
    "        mean=np.sum(tX,axis=0)/tX.shape[0]\n",
    "        std=np.sqrt(np.sum(tX**2,axis=0)/tX.shape[0])\n",
    "    tX=(tX-mean)/std\n",
    "    if train:\n",
    "        return tX,mean,std\n",
    "    else:\n",
    "        return tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_ones(tX_starting):\n",
    "    ones=np.ones(tX_starting.shape[0]).reshape([tX_starting.shape[0],1])\n",
    "    tX=np.concatenate((tX_starting,ones),axis=1)\n",
    "    return tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_data(tX_starting,y,prod_to_exclude=False,train=True,mean=False,std=False,median=False,exclude=False):\n",
    "    full_added_matrix,tX,median=before_poly(tX_starting,median)\n",
    "    tX,prod_to_exclude,dict_cross=build_poly(tX,14,y,exclude=exclude,train=train,prod_to_exclude=prod_to_exclude,exponential=True,cross_products=True,added_matrix_for_cross=full_added_matrix,threshold_cross=0.0)\n",
    "    if train:\n",
    "        tX,mean,std=normalize(tX,train=True)\n",
    "    else:\n",
    "        tX=normalize(tX,mean,std,train=False)\n",
    "    tX=add_ones(tX)\n",
    "    \n",
    "    if train:\n",
    "        return tX,prod_to_exclude,mean,std,median,dict_cross\n",
    "    else:\n",
    "        return tX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tX=tX_starting.copy()\n",
    "y=y_starting.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exc=[]\n",
    "tX=tX_starting.copy()\n",
    "y=y_starting.copy()\n",
    "tX,prod_to_exclude,mean,std,median,dict_cross=process_data(tX,y,train=True,exclude=exc)\n",
    "#tX_test=process_data(tX_test,prod_to_exclude=prod_to_exclude,mean=mean,std=std,train=False,exclude=exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 1372)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    #np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "k_indices=build_k_indices(y,4,1)\n",
    "np.save(\"k_indices\",k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # get k'th subgroup in test, others in train: TODO\n",
    "    # ***************************************************\n",
    "    \n",
    "    loss_tr=[]\n",
    "    loss_te=[]\n",
    "    ac_tr=[]\n",
    "    ac_te=[]\n",
    "    w_vector=[]\n",
    "    for k_index in k_indices:\n",
    "        \n",
    "        x_test=x[k_index]\n",
    "        y_test=y[k_index]\n",
    "        \n",
    "        mask = np.ones(x.shape[0], dtype=bool) # all elements included/True.\n",
    "        mask[k_index] = False              # Set unwanted elements to False\n",
    "\n",
    "        x_train=x[mask]\n",
    "        y_train=y[mask]\n",
    "        exc=[]\n",
    "        x_train,prod_to_exclude,mean,std,median,dict_cross=process_data(x_train,y_train,train=True,exclude=exc)\n",
    "        x_test=process_data(x_test,y_test,prod_to_exclude=prod_to_exclude,mean=mean,std=std,median=median,train=False,exclude=exc)\n",
    "        #print(x_train.shape)\n",
    "\n",
    "        w,mse=ridge_regression(y_train,x_train,lambda_)\n",
    "        #w,mse=least_squares(y_train,x_train)\n",
    "        w_vector.append(w)\n",
    "        \n",
    "        # NEW PART\n",
    "        print('log')\n",
    "        initial_w=w.copy()\n",
    "        \n",
    "        y_log=y_train.copy()\n",
    "        y_log[y_log==-1]=0\n",
    "        gamma_log=0.00000000001\n",
    "        lamb_log=lambda_\n",
    "        w,loss=reg_logistic_regression_newton(y_log,x_train,lamb_log,initial_w,10,gamma_log)\n",
    "        \n",
    "        # END NEW PART\n",
    "        ac_tr.append(evaluate(y_train,x_train,w))\n",
    "        ac_te.append(evaluate(y_test,x_test,w))\n",
    "        print(ac_tr[-1],ac_te[-1])\n",
    "        \n",
    "    #final_w=sum(w_vector)/4\n",
    "        \n",
    "    return ac_tr,ac_te,np.mean(ac_tr), np.mean(ac_te),w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lamb=-3.44444444444e-04\n",
    "#lamb=1e-04\n",
    "# lamb=0.1\n",
    "lamb=-5e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ac_tr,ac_te,mean_tr,mean_te,w=cross_validation(y,tX,k_indices,4,lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mean_te,mean_tr,ac_te,ac_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833108\n"
     ]
    }
   ],
   "source": [
    "# def least_squares(y, tx):\n",
    "#     \"\"\"calculate the least squares solution.\"\"\"\n",
    "#     # returns mse, and optimal weights\n",
    "    \n",
    "#     w=np.linalg.solve(tx.T.dot(tx),tx.T.dot(y))\n",
    "#     mse=sum((y-tx.dot(w))**2)/tx.shape[0]\n",
    "    \n",
    "#     return mse,w\n",
    "\n",
    "#w,loss=least_squares(y,tX)\n",
    "print(evaluate(y,tX,w))\n",
    "#\n",
    "#print(evaluate(y_test,tX_test,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lamb=-5.21111111e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def ridge_regression(y, tx, lamb):\n",
    "#     \"\"\"implement ridge regression.\"\"\"\n",
    "#     # ***************************************************\n",
    "#     # INSERT YOUR CODE HERE\n",
    "#     # ridge regression: TODO\n",
    "#     # ***************************************************\n",
    "#     w=np.linalg.solve(tx.T.dot(tx)+lamb**2*np.identity(tx.shape[1]),tx.T.dot(y))\n",
    "#     #mse=sum((y-tx.dot(w))**2)/tx.shape[0]\n",
    "#     return 1,w\n",
    "\n",
    "w,loss=ridge_regression(y,tX,lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perc_tr=[]\n",
    "perc_te=[]\n",
    "\n",
    "lambdas = np.linspace(-0.00007,-0.00005,10)\n",
    "for i,lamb in enumerate(lambdas):\n",
    "#     w,loss=ridge_regression(y,tX,lamb)\n",
    "    ac_tr,ac_te,mean_tr,mean_te,w=cross_validation(y,tX,k_indices,4,lamb)\n",
    "    perc_tr.append(mean_tr)\n",
    "    perc_te.append(mean_te)\n",
    "    print(mean_tr,mean_te,lamb,ac_te)\n",
    "    \n",
    "#     perc_tr.append(evaluate(y,tX,w))\n",
    "#     perc_te.append(evaluate(y_test,tX_test,w))\n",
    "    \n",
    "    if i%1==0:\n",
    "        print(i)\n",
    "\n",
    "plt.plot(lambdas,perc_tr,label='train',color='r')\n",
    "# plt.plot(lambdas,perc_te,label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perc_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.amax(perc_te))\n",
    "print(np.median(perc_te))\n",
    "b=np.argmax(perc_te)\n",
    "best_lamb=lambdas[b]\n",
    "\n",
    "mse,w=ridge_regression(y,tX,best_lamb)\n",
    "w.shape\n",
    "best_lamb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lamb=3.35e-05\n",
    "lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perc_te[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best so far\n",
    "- Degree 10 - 4 exp - all done, ridge regression: 0.82956\n",
    "- Degree 10 - 3 exp - all done, ridge regression: 0.829008\n",
    "- Degree 14 - 2 exp - all done, ridge regression: 0.82896\n",
    "- Degree 12 - 2 exp - all done, ridge regression: 0.828936\n",
    "- Degree 12 - all done, ridge regression: 0.828784\n",
    "- Degree 10 - 2 exp - all done, ridge regression: 0.828408\n",
    "- Degree 10 - exp - all done, ridge regression: 0.827816\n",
    "- Degree 10 - all done, ridge regression: 0.82717600000000002\n",
    "- Degree 6 - all done, ridge regression: 0.81543199999999993\n",
    "- Degree 8 - all done, ridge regression: 0.82291999999999998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cor=np.corrcoef(tX,rowvar=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 25, 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.matshow(cor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main_loop():\n",
    "    list_tr=[]\n",
    "    list_te=[]\n",
    "    tX,tX_test,y,y_test=split_data(tX_starting,y_starting,0.5,1)\n",
    "    exclude_list=[]\n",
    "    tX,prod_to_exclude,mean,std,dict_cross=process_data(tX,train=True,exclude=exclude_list)\n",
    "    tX_test=process_data(tX_test,prod_to_exclude=prod_to_exclude,mean=mean,std=std,train=False,exclude=exclude_list)\n",
    "    for i in range(tX.shape[1]):\n",
    "        if i%10==0:\n",
    "            print(i)\n",
    "        tX_new=np.delete(tX,i,axis=1)\n",
    "        tX_test_new=np.delete(tX_test,i,axis=1)\n",
    "    \n",
    "        mse,w=least_squares(y,tX_new)\n",
    "        list_tr.append(evaluate(y,tX_new,w))\n",
    "        list_te.append(evaluate(y_test,tX_test_new,w))\n",
    "    return list_tr,list_te\n",
    "list_tr,list_te=main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exclude_list=list(sum([np.array(list_te)>0.8208]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,num in enumerate(exclude_list):\n",
    "    if num==1:\n",
    "        exclude_list[i]=i\n",
    "exclude_list=[x for x in exclude_list if x!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(exclude_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tX=np.delete(tX,exclude_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tX_test=np.delete(tX_test,exclude_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tX.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Basic implementation of logistic regression using the least squares\n",
    "def logistic_regression(y,tx,tx_test,threshold=0.5):\n",
    "    mse,w=least_squares(y,tx)\n",
    "    \n",
    "    y_prev=tx.dot(w)\n",
    "    y_prev=1/(1+np.exp(-y_prev))\n",
    "    output_train=np.ones(y_prev.shape[0])\n",
    "    output_train[np.where(y_prev<threshold)] = -1\n",
    "    \n",
    "    y_test=tx_test.dot(w)\n",
    "    y_test=1/(1+np.exp(-y_test))\n",
    "    output_test=np.ones(y_test.shape[0])\n",
    "    output_test[np.where(y_test<threshold)] = -1\n",
    "    \n",
    "    return output_train,output_test\n",
    "\n",
    "thresholds=np.linspace(0.48,0.52,101)\n",
    "perc_log_tr=[]\n",
    "perc_log_te=[]\n",
    "for threshold in thresholds:\n",
    "    output_train,output_test=logistic_regression(y_train,tX_train,tX_test,threshold)\n",
    "    perc_log_tr.append(evaluate_prediction(output_train,y_train))\n",
    "    perc_log_te.append(evaluate_prediction(output_test,y_test))\n",
    "\n",
    "    \n",
    "plt.plot(thresholds,perc_log_tr,'r',label='Train')\n",
    "plt.plot(thresholds,perc_log_te,'b',label='Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../../test.csv' # TODO: download train data and supply path here \n",
    "_, tX_final_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tX_final=process_data(tX_final_test,y=y,prod_to_exclude=prod_to_exclude,mean=mean,std=std,median=median,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tX_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../../predictions.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w, tX_final)\n",
    "#y_train,y_test = logistic_regression(y_train,tX_train,tX_final_test,0.48)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
