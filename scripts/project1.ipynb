{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import datetime\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../../train.csv' # TODO: download train data and supply path here \n",
    "y, tX_starting, ids = load_csv_data(DATA_TRAIN_PATH,sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tX[tX==-999]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.314664</td>\n",
       "      <td>-49.023079</td>\n",
       "      <td>49.239819</td>\n",
       "      <td>81.181982</td>\n",
       "      <td>57.895962</td>\n",
       "      <td>-708.420675</td>\n",
       "      <td>-601.237051</td>\n",
       "      <td>-709.356603</td>\n",
       "      <td>2.373100</td>\n",
       "      <td>18.917332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010119</td>\n",
       "      <td>209.797178</td>\n",
       "      <td>0.979176</td>\n",
       "      <td>-348.329567</td>\n",
       "      <td>-399.254314</td>\n",
       "      <td>-399.259788</td>\n",
       "      <td>-692.381204</td>\n",
       "      <td>-709.121609</td>\n",
       "      <td>-709.118631</td>\n",
       "      <td>73.064591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.949205</td>\n",
       "      <td>406.345647</td>\n",
       "      <td>35.344886</td>\n",
       "      <td>40.828691</td>\n",
       "      <td>63.655682</td>\n",
       "      <td>454.480565</td>\n",
       "      <td>657.972302</td>\n",
       "      <td>453.019877</td>\n",
       "      <td>0.782911</td>\n",
       "      <td>22.273494</td>\n",
       "      <td>...</td>\n",
       "      <td>1.812223</td>\n",
       "      <td>126.499506</td>\n",
       "      <td>0.977426</td>\n",
       "      <td>532.962789</td>\n",
       "      <td>489.338286</td>\n",
       "      <td>489.333883</td>\n",
       "      <td>479.875496</td>\n",
       "      <td>453.384624</td>\n",
       "      <td>453.389017</td>\n",
       "      <td>98.015662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.329000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>13.678000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>78.100750</td>\n",
       "      <td>19.241000</td>\n",
       "      <td>59.388750</td>\n",
       "      <td>14.068750</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>2.841000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>123.017500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>105.012000</td>\n",
       "      <td>46.524000</td>\n",
       "      <td>73.752000</td>\n",
       "      <td>38.467500</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>2.491500</td>\n",
       "      <td>12.315500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>179.739000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.960000</td>\n",
       "      <td>-1.872000</td>\n",
       "      <td>-2.093000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>40.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.606250</td>\n",
       "      <td>73.598000</td>\n",
       "      <td>92.259000</td>\n",
       "      <td>79.169000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>83.446000</td>\n",
       "      <td>-4.593000</td>\n",
       "      <td>2.961000</td>\n",
       "      <td>27.591000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.561000</td>\n",
       "      <td>263.379250</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>75.349000</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>33.703000</td>\n",
       "      <td>-2.457000</td>\n",
       "      <td>-2.275000</td>\n",
       "      <td>109.933750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1192.026000</td>\n",
       "      <td>690.075000</td>\n",
       "      <td>1349.351000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>8.503000</td>\n",
       "      <td>4974.979000</td>\n",
       "      <td>16.690000</td>\n",
       "      <td>5.684000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2003.976000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1120.573000</td>\n",
       "      <td>4.499000</td>\n",
       "      <td>3.141000</td>\n",
       "      <td>721.456000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>1633.433000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Prediction   DER_mass_MMC  DER_mass_transverse_met_lep  \\\n",
       "count  250000.000000  250000.000000                250000.000000   \n",
       "mean       -0.314664     -49.023079                    49.239819   \n",
       "std         0.949205     406.345647                    35.344886   \n",
       "min        -1.000000    -999.000000                     0.000000   \n",
       "25%        -1.000000      78.100750                    19.241000   \n",
       "50%        -1.000000     105.012000                    46.524000   \n",
       "75%         1.000000     130.606250                    73.598000   \n",
       "max         1.000000    1192.026000                   690.075000   \n",
       "\n",
       "        DER_mass_vis       DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  \\\n",
       "count  250000.000000  250000.000000         250000.000000     250000.000000   \n",
       "mean       81.181982      57.895962           -708.420675       -601.237051   \n",
       "std        40.828691      63.655682            454.480565        657.972302   \n",
       "min         6.329000       0.000000           -999.000000       -999.000000   \n",
       "25%        59.388750      14.068750           -999.000000       -999.000000   \n",
       "50%        73.752000      38.467500           -999.000000       -999.000000   \n",
       "75%        92.259000      79.169000              0.490000         83.446000   \n",
       "max      1349.351000    2834.999000              8.503000       4974.979000   \n",
       "\n",
       "       DER_prodeta_jet_jet  DER_deltar_tau_lep     DER_pt_tot       ...        \\\n",
       "count        250000.000000       250000.000000  250000.000000       ...         \n",
       "mean           -709.356603            2.373100      18.917332       ...         \n",
       "std             453.019877            0.782911      22.273494       ...         \n",
       "min            -999.000000            0.208000       0.000000       ...         \n",
       "25%            -999.000000            1.810000       2.841000       ...         \n",
       "50%            -999.000000            2.491500      12.315500       ...         \n",
       "75%              -4.593000            2.961000      27.591000       ...         \n",
       "max              16.690000            5.684000    2834.999000       ...         \n",
       "\n",
       "         PRI_met_phi  PRI_met_sumet    PRI_jet_num  PRI_jet_leading_pt  \\\n",
       "count  250000.000000  250000.000000  250000.000000       250000.000000   \n",
       "mean       -0.010119     209.797178       0.979176         -348.329567   \n",
       "std         1.812223     126.499506       0.977426          532.962789   \n",
       "min        -3.142000      13.678000       0.000000         -999.000000   \n",
       "25%        -1.575000     123.017500       0.000000         -999.000000   \n",
       "50%        -0.024000     179.739000       1.000000           38.960000   \n",
       "75%         1.561000     263.379250       2.000000           75.349000   \n",
       "max         3.142000    2003.976000       3.000000         1120.573000   \n",
       "\n",
       "       PRI_jet_leading_eta  PRI_jet_leading_phi  PRI_jet_subleading_pt  \\\n",
       "count        250000.000000        250000.000000          250000.000000   \n",
       "mean           -399.254314          -399.259788            -692.381204   \n",
       "std             489.338286           489.333883             479.875496   \n",
       "min            -999.000000          -999.000000            -999.000000   \n",
       "25%            -999.000000          -999.000000            -999.000000   \n",
       "50%              -1.872000            -2.093000            -999.000000   \n",
       "75%               0.433000             0.503000              33.703000   \n",
       "max               4.499000             3.141000             721.456000   \n",
       "\n",
       "       PRI_jet_subleading_eta  PRI_jet_subleading_phi  PRI_jet_all_pt  \n",
       "count           250000.000000           250000.000000   250000.000000  \n",
       "mean              -709.121609             -709.118631       73.064591  \n",
       "std                453.384624              453.389017       98.015662  \n",
       "min               -999.000000             -999.000000        0.000000  \n",
       "25%               -999.000000             -999.000000        0.000000  \n",
       "50%               -999.000000             -999.000000       40.512500  \n",
       "75%                 -2.457000               -2.275000      109.933750  \n",
       "max                  4.500000                3.142000     1633.433000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General data description\n",
    "pd_data=pd.read_csv(DATA_TRAIN_PATH)\n",
    "pd_data=pd_data.replace({'s':1,'b':-1})\n",
    "del pd_data['Id']\n",
    "pd_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction                          0\n",
       "DER_mass_MMC                    38114\n",
       "DER_mass_transverse_met_lep         0\n",
       "DER_mass_vis                        0\n",
       "DER_pt_h                            0\n",
       "DER_deltaeta_jet_jet           177457\n",
       "DER_mass_jet_jet               177457\n",
       "DER_prodeta_jet_jet            177457\n",
       "DER_deltar_tau_lep                  0\n",
       "DER_pt_tot                          0\n",
       "DER_sum_pt                          0\n",
       "DER_pt_ratio_lep_tau                0\n",
       "DER_met_phi_centrality              0\n",
       "DER_lep_eta_centrality         177457\n",
       "PRI_tau_pt                          0\n",
       "PRI_tau_eta                         0\n",
       "PRI_tau_phi                         0\n",
       "PRI_lep_pt                          0\n",
       "PRI_lep_eta                         0\n",
       "PRI_lep_phi                         0\n",
       "PRI_met                             0\n",
       "PRI_met_phi                         0\n",
       "PRI_met_sumet                       0\n",
       "PRI_jet_num                         0\n",
       "PRI_jet_leading_pt              99913\n",
       "PRI_jet_leading_eta             99913\n",
       "PRI_jet_leading_phi             99913\n",
       "PRI_jet_subleading_pt          177457\n",
       "PRI_jet_subleading_eta         177457\n",
       "PRI_jet_subleading_phi         177457\n",
       "PRI_jet_all_pt                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of nan\n",
    "pd_data[pd_data==-999].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction                     1.000000\n",
       "DER_mass_MMC                   0.161623\n",
       "DER_mass_transverse_met_lep   -0.351428\n",
       "DER_mass_vis                  -0.014055\n",
       "DER_pt_h                       0.192526\n",
       "DER_deltaeta_jet_jet           0.227925\n",
       "DER_mass_jet_jet               0.227832\n",
       "DER_prodeta_jet_jet           -0.189891\n",
       "DER_deltar_tau_lep             0.012245\n",
       "DER_pt_tot                    -0.015287\n",
       "DER_sum_pt                     0.153236\n",
       "DER_pt_ratio_lep_tau          -0.195398\n",
       "DER_met_phi_centrality         0.271752\n",
       "DER_lep_eta_centrality         0.223175\n",
       "PRI_tau_pt                     0.235238\n",
       "PRI_tau_eta                   -0.000943\n",
       "PRI_tau_phi                   -0.004403\n",
       "PRI_lep_pt                    -0.031948\n",
       "PRI_lep_eta                    0.001516\n",
       "PRI_lep_phi                    0.004125\n",
       "PRI_met                        0.022466\n",
       "PRI_met_phi                    0.007475\n",
       "PRI_met_sumet                  0.135520\n",
       "PRI_jet_num                    0.133549\n",
       "PRI_jet_leading_pt             0.165253\n",
       "PRI_jet_leading_eta            0.000072\n",
       "PRI_jet_leading_phi           -0.000827\n",
       "PRI_jet_subleading_pt          0.110981\n",
       "PRI_jet_subleading_eta        -0.000014\n",
       "PRI_jet_subleading_phi        -0.003656\n",
       "PRI_jet_all_pt                 0.134296\n",
       "Name: Prediction, dtype: float64"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation matrix\n",
    "pd_data2=pd_data.replace({-999:0})\n",
    "pd_data2=pd_data.replace({-999:0})\n",
    "corr_matrix=pd_data2.corr()\n",
    "corr_matrix.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6ab79831d0>"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRIFjEiAKHJMAUeD+H6l4iLCW83N7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ac50fdef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(pd_data2.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 177457.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,     310.,   61764.,   10469.]),\n",
       " array([-999.        , -984.49014286, -969.98028571, -955.47042857,\n",
       "        -940.96057143, -926.45071429, -911.94085714, -897.431     ,\n",
       "        -882.92114286, -868.41128571, -853.90142857, -839.39157143,\n",
       "        -824.88171429, -810.37185714, -795.862     , -781.35214286,\n",
       "        -766.84228571, -752.33242857, -737.82257143, -723.31271429,\n",
       "        -708.80285714, -694.293     , -679.78314286, -665.27328571,\n",
       "        -650.76342857, -636.25357143, -621.74371429, -607.23385714,\n",
       "        -592.724     , -578.21414286, -563.70428571, -549.19442857,\n",
       "        -534.68457143, -520.17471429, -505.66485714, -491.155     ,\n",
       "        -476.64514286, -462.13528571, -447.62542857, -433.11557143,\n",
       "        -418.60571429, -404.09585714, -389.586     , -375.07614286,\n",
       "        -360.56628571, -346.05642857, -331.54657143, -317.03671429,\n",
       "        -302.52685714, -288.017     , -273.50714286, -258.99728571,\n",
       "        -244.48742857, -229.97757143, -215.46771429, -200.95785714,\n",
       "        -186.448     , -171.93814286, -157.42828571, -142.91842857,\n",
       "        -128.40857143, -113.89871429,  -99.38885714,  -84.879     ,\n",
       "         -70.36914286,  -55.85928571,  -41.34942857,  -26.83957143,\n",
       "         -12.32971429,    2.18014286,   16.69      ]),\n",
       " <a list of 70 Patch objects>)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEACAYAAAByG0uxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nc4iYmVk2h4iZmWX7/1fykKU3F1TZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ab07136d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(tX_starting[:,6],bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 28)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_columns=[]\n",
    "for i in range(tX_starting.shape[1]):\n",
    "    coeff=np.corrcoef(y,tX_starting[:,i])[0,1]\n",
    "    if abs(coeff)<0.003:\n",
    "        drop_columns.append(i)\n",
    "tX=np.delete(tX_starting,drop_columns,axis=1)\n",
    "tX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tX[tX==-999]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalizing\n",
    "#mean=np.sum(tX,axis=0)/tX.shape[0]\n",
    "#std=np.sqrt(np.sum(tX**2,axis=0)/tX.shape[0])\n",
    "#tX=(tX-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 28)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    print(x.shape)\n",
    "    train_elements=int(ratio*x.shape[0])\n",
    "    test_elements=x.shape[0]-train_elements\n",
    "    print(train_elements,test_elements)\n",
    "    indices = np.random.permutation(x.shape[0])\n",
    "    training_idx, test_idx = indices[:train_elements], indices[train_elements:]\n",
    "    x_train, x_test = x[training_idx], x[test_idx]\n",
    "    y_train, y_test = y[training_idx], y[test_idx]\n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 28)\n",
      "125000 125000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(125000, 28)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_train,tX_test,y_train,y_test=split_data(tX,y,0.5,1)\n",
    "tX_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(y, tX, w):\n",
    "    \"\"\"Calculate the loss.\n",
    "\n",
    "    You can calculate the loss using mse or mae.\n",
    "    \"\"\"\n",
    "    error= y-tX.dot(w)\n",
    "    square=np.sum(error**2)/error.shape[0]\n",
    "    return square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_gradient(y, tX, w):\n",
    "    \"\"\"Compute the gradient.\"\"\"\n",
    "    N=tX.shape[0]\n",
    "    error=y-tX.dot(w)\n",
    "    gradient=-1.0/N*(np.transpose(tX).dot(error))\n",
    "    return gradient\n",
    "        \n",
    "compute_gradient(y_train,tX_train,np.zeros([tX_train.shape[1]])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(y, tX, initial_w, max_iters, gamma): \n",
    "    \"\"\"Gradient descent algorithm.\"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # Compute gradient and loss\n",
    "        gradient=compute_gradient(y,tX,w)\n",
    "        loss=compute_loss(y,tX,w)\n",
    "        # Update w by gradient\n",
    "        w=w-gamma*gradient\n",
    "        # store w and loss\n",
    "        ws.append(np.copy(w))\n",
    "        losses.append(loss)\n",
    "        print(\"Gradient Descent({bi}/{ti}): loss={l}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss))\n",
    "\n",
    "    print(w.shape)\n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient for batch data.\"\"\"\n",
    "    N=tx.shape[0]\n",
    "    error=y-tx.dot(w)\n",
    "    gradient=-1.0/N*(np.transpose(tx).dot(error))\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_epochs, gamma):\n",
    "    \"\"\"Stochastic gradient descent algorithm.\"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    y_shuffle=[]\n",
    "    tx_shuffle=[]\n",
    "    for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "        y_shuffle.append(minibatch_y)\n",
    "        tx_shuffle.append(minibatch_tx)\n",
    "    for n_iter in range(max_epochs):\n",
    "        # compute stochastic gradient\n",
    "        gradient=compute_stoch_gradient(y_shuffle[n_iter],tx_shuffle[n_iter],w)\n",
    "        loss=compute_loss(y,tx,w)\n",
    "        # update w\n",
    "        w=w-gamma*gradient\n",
    "        # store w and loss\n",
    "        ws.append(np.copy(w))\n",
    "        losses.append(loss)\n",
    "        print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "\n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/49): loss=50511915.38288502\n",
      "Gradient Descent(1/49): loss=156329308338.88947\n",
      "Gradient Descent(2/49): loss=496301113835573.94\n",
      "Gradient Descent(3/49): loss=1.5757085075368845e+18\n",
      "Gradient Descent(4/49): loss=5.002725024739957e+21\n",
      "Gradient Descent(5/49): loss=1.5883177369305333e+25\n",
      "Gradient Descent(6/49): loss=5.04275813879282e+28\n",
      "Gradient Descent(7/49): loss=1.6010278708783432e+32\n",
      "Gradient Descent(8/49): loss=5.0831116083288145e+35\n",
      "Gradient Descent(9/49): loss=1.6138397146423256e+39\n",
      "Gradient Descent(10/49): loss=5.1237879968822956e+42\n",
      "Gradient Descent(11/49): loss=1.626754082130988e+46\n",
      "Gradient Descent(12/49): loss=5.164789888535705e+49\n",
      "Gradient Descent(13/49): loss=1.6397717937659823e+53\n",
      "Gradient Descent(14/49): loss=5.206119888049968e+56\n",
      "Gradient Descent(15/49): loss=1.652893676534202e+60\n",
      "Gradient Descent(16/49): loss=5.247780621030008e+63\n",
      "Gradient Descent(17/49): loss=1.6661205640403e+67\n",
      "Gradient Descent(18/49): loss=5.289774734091517e+70\n",
      "Gradient Descent(19/49): loss=1.6794532965596498e+74\n",
      "Gradient Descent(20/49): loss=5.332104895029114e+77\n",
      "Gradient Descent(21/49): loss=1.6928927210917302e+81\n",
      "Gradient Descent(22/49): loss=5.374773792985775e+84\n",
      "Gradient Descent(23/49): loss=1.7064396914139374e+88\n",
      "Gradient Descent(24/49): loss=5.417784138623749e+91\n",
      "Gradient Descent(25/49): loss=1.7200950681358068e+95\n",
      "Gradient Descent(26/49): loss=5.461138664296653e+98\n",
      "Gradient Descent(27/49): loss=1.733859718753702e+102\n",
      "Gradient Descent(28/49): loss=5.504840124223161e+105\n",
      "Gradient Descent(29/49): loss=1.7477345177059216e+109\n",
      "Gradient Descent(30/49): loss=5.548891294661913e+112\n",
      "Gradient Descent(31/49): loss=1.7617203464282447e+116\n",
      "Gradient Descent(32/49): loss=5.593294974087891e+119\n",
      "Gradient Descent(33/49): loss=1.77581809340993e+123\n",
      "Gradient Descent(34/49): loss=5.63805398337021e+126\n",
      "Gradient Descent(35/49): loss=1.7900286542501624e+130\n",
      "Gradient Descent(36/49): loss=5.68317116595131e+133\n",
      "Gradient Descent(37/49): loss=1.8043529317149444e+137\n",
      "Gradient Descent(38/49): loss=5.728649388027614e+140\n",
      "Gradient Descent(39/49): loss=1.818791835794443e+144\n",
      "Gradient Descent(40/49): loss=5.774491538731577e+147\n",
      "Gradient Descent(41/49): loss=1.833346283760818e+151\n",
      "Gradient Descent(42/49): loss=5.820700530315272e+154\n",
      "Gradient Descent(43/49): loss=1.848017200226462e+158\n",
      "Gradient Descent(44/49): loss=5.867279298335379e+161\n",
      "Gradient Descent(45/49): loss=1.862805517202778e+165\n",
      "Gradient Descent(46/49): loss=5.9142308018396305e+168\n",
      "Gradient Descent(47/49): loss=1.877712174159351e+172\n",
      "Gradient Descent(48/49): loss=5.9615580235548645e+175\n",
      "Gradient Descent(49/49): loss=1.8927381180836522e+179\n",
      "(28,)\n",
      "Gradient Descent: execution time=0.675 seconds\n",
      "6.00010526872e+182\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.00001\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.ones(tX.shape[1])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gradient_losses, w = gradient_descent(y, tX, w_initial, max_iters, gamma)\n",
    "#gradient_losses, w = stochastic_gradient_descent(y_train, tX_train, w_initial,30, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Gradient Descent: execution time={t:.3f} seconds\".format(t=exection_time))\n",
    "\n",
    "print(sum((y_test-tX_test.dot(w))**2)/tX_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67968773238 [  7.87914737e-05  -7.09725507e-03  -6.07515452e-03  -4.68694696e-04\n",
      "  -1.67035418e-02   4.67914022e-04  -2.63478247e-02   3.29199923e-01\n",
      "   1.23287753e-04  -6.43881725e+00  -2.24528984e-01   9.61048944e-02\n",
      "   6.35356661e-02   6.44691339e+00  -5.23767053e-04   6.45180891e+00\n",
      "  -1.14343416e-04   3.73705921e-03  -1.40895472e-04  -5.51527503e-04\n",
      "  -3.35039066e-01  -1.49664999e-03   3.75586626e-04   1.57023333e-03\n",
      "  -1.61263588e-03  -5.96948193e-03  -1.29102310e-02   6.43930089e+00]\n"
     ]
    }
   ],
   "source": [
    "def least_squares(y, tx):\n",
    "    \"\"\"calculate the least squares solution.\"\"\"\n",
    "    # returns mse, and optimal weights\n",
    "    \n",
    "    w=np.linalg.solve(tx.T.dot(tx),tx.T.dot(y))\n",
    "    mse=sum((y-tx.dot(w))**2)/tx.shape[0]\n",
    "    \n",
    "    return mse,w\n",
    "    \n",
    "mse,w=least_squares(y_train,tX_train)\n",
    "print(mse,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67968773238 [  7.87914737e-05  -7.09725507e-03  -6.07515452e-03  -4.68694696e-04\n",
      "  -1.67035418e-02   4.67914022e-04  -2.63478247e-02   3.29199923e-01\n",
      "   1.23287753e-04  -6.43881725e+00  -2.24528984e-01   9.61048944e-02\n",
      "   6.35356661e-02   6.44691339e+00  -5.23767053e-04   6.45180891e+00\n",
      "  -1.14343416e-04   3.73705921e-03  -1.40895472e-04  -5.51527503e-04\n",
      "  -3.35039066e-01  -1.49664999e-03   3.75586626e-04   1.57023333e-03\n",
      "  -1.61263588e-03  -5.96948193e-03  -1.29102310e-02   6.43930089e+00]\n"
     ]
    }
   ],
   "source": [
    "def ridge_regression(y, tx, lamb):\n",
    "    \"\"\"implement ridge regression.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # ridge regression: TODO\n",
    "    # ***************************************************\n",
    "    w=np.linalg.solve(tx.T.dot(tx)+lamb**2*np.identity(tx.shape[1]),tx.T.dot(y))\n",
    "    mse=sum((y-tx.dot(w))**2)/tx.shape[0]\n",
    "    return mse,w\n",
    "\n",
    "mse,w=ridge_regression(y_train,tX_train,0)\n",
    "print(mse,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_predictions(tX,w):\n",
    "    prediction=tX.dot(w)\n",
    "    prediction[np.where(prediction <= 0)] = -1\n",
    "    prediction[np.where(prediction > 0)] = 1\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_prediction(prediction,y):\n",
    "    print((sum(y*prediction)/y.shape[0]+1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744176\n"
     ]
    }
   ],
   "source": [
    "tX_test_post=np.copy(tX_test)\n",
    "tX_test_post[tX_test_post==-999]=0\n",
    "prediction=compute_predictions(tX_test,w)\n",
    "evaluate_prediction(prediction,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.706787284653\n",
      "[ 0.28976197  0.27222802 -0.27184157 ..., -0.52214609 -0.0157873\n",
      " -0.55324264]\n"
     ]
    }
   ],
   "source": [
    "print(sum((y_test-tX_test.dot(w))**2)/tX_test.shape[0])\n",
    "print(tX_test.dot(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../../test.csv' # TODO: download train data and supply path here \n",
    "_, tX_final_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. ..., -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = '../../predictions.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w, tX_final_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
