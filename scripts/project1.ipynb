{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import datetime\n",
    "from helpers import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../../train.csv' # TODO: download train data and supply path here \n",
    "y_starting, tX_starting, ids = load_csv_data(DATA_TRAIN_PATH,sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete columns with low correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def drop_col(tX_starting):\n",
    "    drop_columns=[]\n",
    "    #for i in range(tX_starting.shape[1]):\n",
    "    #    coeff=np.corrcoef(y,tX_starting[:,i])[0,1]\n",
    "    #    if abs(coeff)<0.000:\n",
    "    #        drop_columns.append(i)\n",
    "\n",
    "\n",
    "    tX=np.delete(tX_starting,drop_columns,axis=1)\n",
    "    return tX\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replace_nan(tX_starting,median=False):\n",
    "    tX=tX_starting.copy()\n",
    "    nan_position=[tX[:,[0,4,23]]!=-999][0]*1\n",
    "\n",
    "    for col in range(tX.shape[1]):\n",
    "        column=tX[:,col][tX[:,col]!=-999]\n",
    "        if median==False:\n",
    "            mean=column.mean()\n",
    "            median=np.median(column)\n",
    "\n",
    "        tX[:,col][tX[:,col]==-999]=median    \n",
    "    \n",
    "    return nan_position,tX,median\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def categorical_variables(tX_starting):\n",
    "    tX=tX_starting.copy()\n",
    "    \n",
    "    cat_variable=22\n",
    "    values=[0,1,2]\n",
    "\n",
    "    added_matrix=np.zeros([tX.shape[0],3])\n",
    "    added_matrix[:,0]=np.array([tX[:,22]==0])\n",
    "    added_matrix[:,1]=np.array([tX[:,22]==1])\n",
    "    added_matrix[:,2]=np.array([tX[:,22]==2])\n",
    "    \n",
    "    tX=np.delete(tX,[22],axis=1)\n",
    "    \n",
    "    return added_matrix,tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def before_poly(tX_starting,median=False):\n",
    "    tX=drop_col(tX_starting)\n",
    "    nan_position,tX,median=replace_nan(tX,median)\n",
    "    added_matrix,tX=categorical_variables(tX)\n",
    "    full_added_matrix=np.concatenate((added_matrix,nan_position),axis=1)\n",
    "    return full_added_matrix,tX,median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_poly(tX,degree,y,prod_to_exclude=False,train=True,columns_to_consider=False,exponential=False,cross_products=False,added_matrix_for_cross=False,threshold_power=0.0,threshold_cross=0.00,exclude=False):\n",
    "    if not columns_to_consider:\n",
    "        columns_to_consider=range(tX.shape[1])\n",
    "    if not prod_to_exclude:\n",
    "        prod_to_exclude=[]\n",
    "    if exclude==False:\n",
    "        exclude=[]\n",
    "    dict_cross={}\n",
    "    \n",
    "    columns_to_consider=[x for x in columns_to_consider if x not in exclude]\n",
    "    columns_to_consider=np.array(columns_to_consider)\n",
    "    # Add power of the matrix\n",
    "    final_list=[]\n",
    "    for i in range(2,degree+1):\n",
    "        #corr=np.corrcoef(tX[:,columns_to_consider]**i,y,rowvar=0)[:-1,-1]\n",
    "        #cols=abs(corr)>threshold_power\n",
    "        #cols=columns_to_consider[cols]\n",
    "        cols=columns_to_consider\n",
    "        tX=np.concatenate((tX,tX[:,cols]**i),axis=1)\n",
    "        if i%2==1:\n",
    "            tX=np.concatenate((tX,np.sqrt(abs(tX[:,cols]**i))),axis=1)\n",
    "    if exponential:\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/100)),axis=1)\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/80)),axis=1)\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/60)),axis=1)\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/50)),axis=1)\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/40)),axis=1)\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/20)),axis=1)\n",
    "#         tX=np.concatenate((tX,tX[:,cols]**(1.0/5)),axis=1)\n",
    "#         tX=np.concatenate((tX,tX[:,cols]**(1.0/7)),axis=1)\n",
    "\n",
    "    if cross_products:\n",
    "        if added_matrix_for_cross.any():\n",
    "            # Add to columns to consider\n",
    "            for i in range(tX.shape[1],tX.shape[1]+added_matrix_for_cross.shape[1]):\n",
    "                columns_to_consider=np.append(columns_to_consider,i)\n",
    "            # Concatenate\n",
    "            tX=np.concatenate((tX,added_matrix_for_cross),axis=1)\n",
    "            final_list.append(tX)\n",
    "        start_cross=tX.shape[1]\n",
    "        for i,col1 in enumerate(columns_to_consider):\n",
    "            for j,col2 in enumerate(columns_to_consider):\n",
    "                if j>i and (i,j) not in prod_to_exclude:\n",
    "                    if train:\n",
    "                        prod=tX[:,col1]*tX[:,col2]\n",
    "                        corr=np.corrcoef(prod,y)[0,1]\n",
    "                        if abs(corr)>threshold_cross:\n",
    "                            final_list.append(prod.reshape([prod.shape[0],1]))\n",
    "\n",
    "                            #print(start_cross,type(start_cross))\n",
    "                            dict_cross[start_cross]=tuple([i,j])\n",
    "                            start_cross+=1\n",
    "                        else:\n",
    "                            prod_to_exclude.append((i,j))\n",
    "                    else:\n",
    "                        prod=tX[:,col1]*tX[:,col2]\n",
    "                        final_list.append(prod.reshape([prod.shape[0],1]))\n",
    "        final_tuple=tuple(final_list)\n",
    "        tX=np.concatenate(final_tuple,axis=1)\n",
    "    return tX,prod_to_exclude,dict_cross\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(tX,mean=False,std=False,train=False):# Normalizing\n",
    "    if train:\n",
    "        mean=np.sum(tX,axis=0)/tX.shape[0]\n",
    "        std=np.sqrt(np.sum(tX**2,axis=0)/tX.shape[0])\n",
    "    tX=(tX-mean)/std\n",
    "    if train:\n",
    "        return tX,mean,std\n",
    "    else:\n",
    "        return tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_ones(tX_starting):\n",
    "    ones=np.ones(tX_starting.shape[0]).reshape([tX_starting.shape[0],1])\n",
    "    tX=np.concatenate((tX_starting,ones),axis=1)\n",
    "    return tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_data(tX_starting,y,prod_to_exclude=False,train=True,mean=False,std=False,median=False,exclude=False):\n",
    "    full_added_matrix,tX,median=before_poly(tX_starting,median)\n",
    "    tX,prod_to_exclude,dict_cross=build_poly(tX,14,y,exclude=exclude,train=train,prod_to_exclude=prod_to_exclude,exponential=True,cross_products=True,added_matrix_for_cross=full_added_matrix,threshold_cross=0.0)\n",
    "    if train:\n",
    "        tX,mean,std=normalize(tX,train=True)\n",
    "    else:\n",
    "        tX=normalize(tX,mean,std,train=False)\n",
    "    tX=add_ones(tX)\n",
    "    \n",
    "    if train:\n",
    "        return tX,prod_to_exclude,mean,std,median,dict_cross\n",
    "    else:\n",
    "        return tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prod_to_exclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tX=tX_starting.copy()\n",
    "y=y_starting.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/anaconda3/lib/python3.5/site-packages/numpy/lib/function_base.py:2569: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/stefano/anaconda3/lib/python3.5/site-packages/numpy/lib/function_base.py:2570: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "exc=[]\n",
    "tX=tX_starting.copy()\n",
    "y=y_starting.copy()\n",
    "tX,prod_to_exclude,mean,std,median,dict_cross=process_data(tX,y,train=True,exclude=exc)\n",
    "#tX_test=process_data(tX_test,prod_to_exclude=prod_to_exclude,mean=mean,std=std,train=False,exclude=exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 1349)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    #np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "k_indices=build_k_indices(y,4,1)\n",
    "np.save(\"k_indices\",k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # get k'th subgroup in test, others in train: TODO\n",
    "    # ***************************************************\n",
    "    \n",
    "    loss_tr=[]\n",
    "    loss_te=[]\n",
    "    ac_tr=[]\n",
    "    ac_te=[]\n",
    "    w_vector=[]\n",
    "    for k_index in k_indices:\n",
    "        \n",
    "        x_test=x[k_index]\n",
    "        y_test=y[k_index]\n",
    "        \n",
    "        mask = np.ones(x.shape[0], dtype=bool) # all elements included/True.\n",
    "        mask[k_index] = False              # Set unwanted elements to False\n",
    "\n",
    "        x_train=x[mask]\n",
    "        y_train=y[mask]\n",
    "        exc=[]\n",
    "        x_train,prod_to_exclude,mean,std,median,dict_cross=process_data(x_train,y_train,train=True,exclude=exc)\n",
    "        x_test=process_data(x_test,y_test,prod_to_exclude=prod_to_exclude,mean=mean,std=std,median=median,train=False,exclude=exc)\n",
    "        #print(x_train.shape)\n",
    "\n",
    "        w,mse=ridge_regression(y_train,x_train,lambda_)\n",
    "        #w,mse=least_squares(y_train,x_train)\n",
    "        w_vector.append(w)\n",
    "        ac_tr.append(evaluate(y_train,x_train,w))\n",
    "        ac_te.append(evaluate(y_test,x_test,w))\n",
    "        \n",
    "    #final_w=sum(w_vector)/4\n",
    "        \n",
    "    return ac_tr,ac_te,np.mean(ac_tr), np.mean(ac_te),w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lamb=-3.44444444444e-04\n",
    "#lamb=1e-04\n",
    "# lamb=0.1\n",
    "lamb=-5e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ac_tr,ac_te,mean_tr,mean_te,w=cross_validation(y,tX,k_indices,4,lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mean_te,mean_tr,ac_te,ac_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833172\n"
     ]
    }
   ],
   "source": [
    "# def least_squares(y, tx):\n",
    "#     \"\"\"calculate the least squares solution.\"\"\"\n",
    "#     # returns mse, and optimal weights\n",
    "    \n",
    "#     w=np.linalg.solve(tx.T.dot(tx),tx.T.dot(y))\n",
    "#     mse=sum((y-tx.dot(w))**2)/tx.shape[0]\n",
    "    \n",
    "#     return mse,w\n",
    "\n",
    "#w,loss=least_squares(y,tX)\n",
    "print(evaluate(y,tX,w))\n",
    "#\n",
    "#print(evaluate(y_test,tX_test,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lamb=-4.11111111e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def ridge_regression(y, tx, lamb):\n",
    "#     \"\"\"implement ridge regression.\"\"\"\n",
    "#     # ***************************************************\n",
    "#     # INSERT YOUR CODE HERE\n",
    "#     # ridge regression: TODO\n",
    "#     # ***************************************************\n",
    "#     w=np.linalg.solve(tx.T.dot(tx)+lamb**2*np.identity(tx.shape[1]),tx.T.dot(y))\n",
    "#     #mse=sum((y-tx.dot(w))**2)/tx.shape[0]\n",
    "#     return 1,w\n",
    "\n",
    "w,loss=ridge_regression(y,tX,lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f77a21084e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEACAYAAAB78OvLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVlqHCpmZpYah4qZmaXm/wPXR+W5FbhhdQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f77a2108ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perc_tr=[]\n",
    "perc_te=[]\n",
    "\n",
    "lambdas = np.linspace(-0.00007,-0.00005,10)\n",
    "for i,lamb in enumerate(lambdas):\n",
    "    w,loss=ridge_regression(y,tX,lamb)\n",
    "#     ac_tr,ac_te,mean_tr,mean_te,w=cross_validation(y,tX,k_indices,4,lamb)\n",
    "#     perc_tr.append(mean_tr)\n",
    "#     perc_te.append(mean_te)\n",
    "#     print(mean_tr,mean_te,lamb)\n",
    "    \n",
    "    perc_tr.append(evaluate(y,tX,w))\n",
    "#     perc_te.append(evaluate(y_test,tX_test,w))\n",
    "    \n",
    "    if i%1==0:\n",
    "        print(i)\n",
    "\n",
    "plt.plot(lambdas,perc_tr,label='train',color='r')\n",
    "# plt.plot(lambdas,perc_te,label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.83288399999999996,\n",
       " 0.83296799999999993,\n",
       " 0.83298000000000005,\n",
       " 0.83312399999999998,\n",
       " 0.83295999999999992,\n",
       " 0.83297599999999994,\n",
       " 0.83302399999999999,\n",
       " 0.72393600000000002,\n",
       " 0.83305200000000001,\n",
       " 0.83317200000000002]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.0000000000000002e-05"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.amax(perc_te))\n",
    "print(np.median(perc_te))\n",
    "b=np.argmax(perc_te)\n",
    "best_lamb=lambdas[b]\n",
    "\n",
    "mse,w=ridge_regression(y,tX,best_lamb)\n",
    "w.shape\n",
    "best_lamb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lamb=3.35e-05\n",
    "lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perc_te[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best so far\n",
    "- Degree 10 - 4 exp - all done, ridge regression: 0.82956\n",
    "- Degree 10 - 3 exp - all done, ridge regression: 0.829008\n",
    "- Degree 14 - 2 exp - all done, ridge regression: 0.82896\n",
    "- Degree 12 - 2 exp - all done, ridge regression: 0.828936\n",
    "- Degree 12 - all done, ridge regression: 0.828784\n",
    "- Degree 10 - 2 exp - all done, ridge regression: 0.828408\n",
    "- Degree 10 - exp - all done, ridge regression: 0.827816\n",
    "- Degree 10 - all done, ridge regression: 0.82717600000000002\n",
    "- Degree 6 - all done, ridge regression: 0.81543199999999993\n",
    "- Degree 8 - all done, ridge regression: 0.82291999999999998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cor=np.corrcoef(tX,rowvar=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 25, 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.matshow(cor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main_loop():\n",
    "    list_tr=[]\n",
    "    list_te=[]\n",
    "    tX,tX_test,y,y_test=split_data(tX_starting,y_starting,0.5,1)\n",
    "    exclude_list=[]\n",
    "    tX,prod_to_exclude,mean,std,dict_cross=process_data(tX,train=True,exclude=exclude_list)\n",
    "    tX_test=process_data(tX_test,prod_to_exclude=prod_to_exclude,mean=mean,std=std,train=False,exclude=exclude_list)\n",
    "    for i in range(tX.shape[1]):\n",
    "        if i%10==0:\n",
    "            print(i)\n",
    "        tX_new=np.delete(tX,i,axis=1)\n",
    "        tX_test_new=np.delete(tX_test,i,axis=1)\n",
    "    \n",
    "        mse,w=least_squares(y,tX_new)\n",
    "        list_tr.append(evaluate(y,tX_new,w))\n",
    "        list_te.append(evaluate(y_test,tX_test_new,w))\n",
    "    return list_tr,list_te\n",
    "list_tr,list_te=main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exclude_list=list(sum([np.array(list_te)>0.8208]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,num in enumerate(exclude_list):\n",
    "    if num==1:\n",
    "        exclude_list[i]=i\n",
    "exclude_list=[x for x in exclude_list if x!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(exclude_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tX=np.delete(tX,exclude_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tX_test=np.delete(tX_test,exclude_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tX.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Basic implementation of logistic regression using the least squares\n",
    "def logistic_regression(y,tx,tx_test,threshold=0.5):\n",
    "    mse,w=least_squares(y,tx)\n",
    "    \n",
    "    y_prev=tx.dot(w)\n",
    "    y_prev=1/(1+np.exp(-y_prev))\n",
    "    output_train=np.ones(y_prev.shape[0])\n",
    "    output_train[np.where(y_prev<threshold)] = -1\n",
    "    \n",
    "    y_test=tx_test.dot(w)\n",
    "    y_test=1/(1+np.exp(-y_test))\n",
    "    output_test=np.ones(y_test.shape[0])\n",
    "    output_test[np.where(y_test<threshold)] = -1\n",
    "    \n",
    "    return output_train,output_test\n",
    "\n",
    "thresholds=np.linspace(0.48,0.52,101)\n",
    "perc_log_tr=[]\n",
    "perc_log_te=[]\n",
    "for threshold in thresholds:\n",
    "    output_train,output_test=logistic_regression(y_train,tX_train,tX_test,threshold)\n",
    "    perc_log_tr.append(evaluate_prediction(output_train,y_train))\n",
    "    perc_log_te.append(evaluate_prediction(output_test,y_test))\n",
    "\n",
    "    \n",
    "plt.plot(thresholds,perc_log_tr,'r',label='Train')\n",
    "plt.plot(thresholds,perc_log_te,'b',label='Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../../test.csv' # TODO: download train data and supply path here \n",
    "_, tX_final_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tX_final=process_data(tX_final_test,y=y,prod_to_exclude=prod_to_exclude,mean=mean,std=std,median=median,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 1349)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1.  1. ...,  1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = '../../predictions.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w, tX_final)\n",
    "#y_train,y_test = logistic_regression(y_train,tX_train,tX_final_test,0.48)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
