{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import datetime\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../../train.csv' # TODO: download train data and supply path here \n",
    "y_starting, tX_starting, ids = load_csv_data(DATA_TRAIN_PATH,sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    250000.000000\n",
       "mean         -0.314664\n",
       "std           0.949205\n",
       "min          -1.000000\n",
       "25%          -1.000000\n",
       "50%          -1.000000\n",
       "75%           1.000000\n",
       "max           1.000000\n",
       "Name: Prediction, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General data description\n",
    "pd_data=pd.read_csv(DATA_TRAIN_PATH)\n",
    "pd_data=pd_data.replace({'s':1,'b':-1})\n",
    "del pd_data['Id']\n",
    "pd_data.Prediction.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of nan\n",
    "pd_data[pd_data==-999].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "pd_data2=pd_data.replace({-999:0})\n",
    "corr_matrix2=pd_data2.corr()\n",
    "corr_matrix2.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_data3=pd_data.replace({-999:-10})\n",
    "corr_matrix3=pd_data3.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_matrix=pd_data.corr()\n",
    "corr_matrix.Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "synthesis=corr_matrix[['Prediction']].copy()\n",
    "synthesis['PredictionCorrected']=corr_matrix2.Prediction\n",
    "synthesis['PredictionNan-10']=corr_matrix3.Prediction\n",
    "synthesis['id']=range(-1,synthesis.shape[0]-1)\n",
    "synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(pd_data2.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(pd_data2[[24]],pd_data2[[22]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names=pd_data.columns.values\n",
    "\n",
    "for i in range(tX_starting.shape[1]):\n",
    "    plt.figure()\n",
    "    plt.title(names[i+1]+\" \"+str(i))\n",
    "    plt.hist(tX_starting[:,i],bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names=pd_data.columns.values\n",
    "\n",
    "for i in range(tX_starting.shape[1]):\n",
    "    plt.figure()\n",
    "    plt.title(names[i+1]+\" \"+str(i))\n",
    "    plt.boxplot(tX_starting[:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    print(x.shape)\n",
    "    train_elements=int(ratio*x.shape[0])\n",
    "    test_elements=x.shape[0]-train_elements\n",
    "    print(train_elements,test_elements)\n",
    "    indices = np.random.permutation(x.shape[0])\n",
    "    training_idx, test_idx = indices[:train_elements], indices[train_elements:]\n",
    "    x_train, x_test = x[training_idx], x[test_idx]\n",
    "    y_train, y_test = y[training_idx], y[test_idx]\n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "125000 125000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(125000, 30)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX,tX_test,y,y_test=split_data(tX_starting,y_starting,0.5,1)\n",
    "tX_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125000, 30)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete columns with low correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def drop_col(tX_starting):\n",
    "    drop_columns=[]\n",
    "    #for i in range(tX_starting.shape[1]):\n",
    "    #    coeff=np.corrcoef(y,tX_starting[:,i])[0,1]\n",
    "    #    if abs(coeff)<0.000:\n",
    "    #        drop_columns.append(i)\n",
    "\n",
    "\n",
    "    tX=np.delete(tX_starting,drop_columns,axis=1)\n",
    "    return tX\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replace_nan(tX_starting):\n",
    "    tX=tX_starting.copy()\n",
    "    nan_position=[tX[:,[0,4,23]]!=-999][0]*1\n",
    "\n",
    "    for col in range(tX.shape[1]):\n",
    "        column=tX[:,col][tX[:,col]!=-999]\n",
    "        mean=column.mean()\n",
    "        median=np.median(column)\n",
    "\n",
    "        tX[:,col][tX[:,col]==-999]=median    \n",
    "    \n",
    "    return nan_position,tX\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def categorical_variables(tX_starting):\n",
    "    tX=tX_starting.copy()\n",
    "    \n",
    "    cat_variable=22\n",
    "    values=[0,1,2]\n",
    "\n",
    "    added_matrix=np.zeros([tX.shape[0],3])\n",
    "    added_matrix[:,0]=np.array([tX[:,22]==0])\n",
    "    added_matrix[:,1]=np.array([tX[:,22]==1])\n",
    "    added_matrix[:,2]=np.array([tX[:,22]==2])\n",
    "    \n",
    "    tX=np.delete(tX,[22],axis=1)\n",
    "    print(tX.shape)\n",
    "    \n",
    "    return added_matrix,tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def before_poly(tX_starting):\n",
    "    tX=drop_col(tX_starting)\n",
    "    nan_position,tX=replace_nan(tX)\n",
    "    added_matrix,tX=categorical_variables(tX)\n",
    "    full_added_matrix=np.concatenate((added_matrix,nan_position),axis=1)\n",
    "    return full_added_matrix,tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 29)\n"
     ]
    }
   ],
   "source": [
    "full_added_matrix,tX=before_poly(tX_starting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_poly(tX,degree,y,prod_to_exclude=False,train=True,columns_to_consider=False,exponential=False,cross_products=False,added_matrix_for_cross=False,threshold_power=0.0,threshold_cross=0.00):\n",
    "    if not columns_to_consider:\n",
    "        columns_to_consider=range(tX.shape[1])\n",
    "    if not prod_to_exclude:\n",
    "        prod_to_exclude=[]\n",
    "    columns_to_consider=np.array(columns_to_consider)\n",
    "    # Add power of the matrix\n",
    "    final_list=[]\n",
    "    for i in range(2,degree+1):\n",
    "        #corr=np.corrcoef(tX[:,columns_to_consider]**i,y,rowvar=0)[:-1,-1]\n",
    "        #cols=abs(corr)>threshold_power\n",
    "        #cols=columns_to_consider[cols]\n",
    "        cols=columns_to_consider\n",
    "        tX=np.concatenate((tX,tX[:,cols]**i),axis=1)\n",
    "    if exponential:\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/100)),axis=1)\n",
    "#        tX=np.concatenate((tX,np.exp(tX[:,cols]/80)),axis=1)\n",
    "#        tX=np.concatenate((tX,np.exp(tX[:,cols]/60)),axis=1)\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/50)),axis=1)\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/40)),axis=1)\n",
    "        tX=np.concatenate((tX,np.exp(tX[:,cols]/20)),axis=1)\n",
    "    if cross_products:\n",
    "        if added_matrix_for_cross.any():\n",
    "            # Add to columns to consider\n",
    "            for i in range(tX.shape[1],tX.shape[1]+added_matrix_for_cross.shape[1]):\n",
    "                columns_to_consider=np.append(columns_to_consider,i)\n",
    "            # Concatenate\n",
    "            tX=np.concatenate((tX,added_matrix_for_cross),axis=1)\n",
    "            final_list.append(tX)\n",
    "        for i,col1 in enumerate(columns_to_consider):\n",
    "            for j,col2 in enumerate(columns_to_consider):\n",
    "                if j>i and (i,j) not in prod_to_exclude:\n",
    "                    if train:\n",
    "                        prod=tX[:,col1]*tX[:,col2]\n",
    "                        corr=np.corrcoef(prod,y)[0,1]\n",
    "                        if abs(corr)>threshold_cross:\n",
    "                            final_list.append(prod.reshape([prod.shape[0],1]))\n",
    "                        else:\n",
    "                            prod_to_exclude.append((i,j))\n",
    "                    else:\n",
    "                        prod=tX[:,col1]*tX[:,col2]\n",
    "                        final_list.append(prod.reshape([prod.shape[0],1]))\n",
    "        final_tuple=tuple(final_list)\n",
    "        tX=np.concatenate(final_tuple,axis=1)\n",
    "    return tX,prod_to_exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-3b8126fd66ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuild_poly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexponential\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcross_products\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madded_matrix_for_cross\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_added_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthreshold_cross\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-e7afd4cea0fe>\u001b[0m in \u001b[0;36mbuild_poly\u001b[1;34m(tX, degree, y, prod_to_exclude, train, columns_to_consider, exponential, cross_products, added_matrix_for_cross, threshold_power, threshold_cross)\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mcolumns_to_consider\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns_to_consider\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m# Concatenate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mtX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madded_matrix_for_cross\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mfinal_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns_to_consider\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "tX=build_poly(tX,10,y,exponential=True,cross_products=True,added_matrix_for_cross=full_added_matrix,threshold_cross=0.0)\n",
    "tX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(tX):# Normalizing\n",
    "    mean=np.sum(tX,axis=0)/tX.shape[0]\n",
    "    std=np.sqrt(np.sum(tX**2,axis=0)/tX.shape[0])\n",
    "    tX=(tX-mean)/std\n",
    "    return tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_ones(tX_starting):\n",
    "    ones=np.ones(tX_starting.shape[0]).reshape([tX_starting.shape[0],1])\n",
    "    tX=np.concatenate((tX_starting,ones),axis=1)\n",
    "    return tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 29)\n",
      "(125000, 29)\n"
     ]
    }
   ],
   "source": [
    "def process_data(tX_starting,prod_to_exclude=False,train=True):\n",
    "    full_added_matrix,tX=before_poly(tX_starting)\n",
    "    tX,prod_to_exclude=build_poly(tX,10,y,train=train,prod_to_exclude=prod_to_exclude,exponential=True,cross_products=False,added_matrix_for_cross=full_added_matrix,threshold_cross=0.0)\n",
    "    tX=normalize(tX)\n",
    "    tX=add_ones(tX)\n",
    "    return tX,prod_to_exclude\n",
    "    \n",
    "tX,prod_to_exclude=process_data(tX)\n",
    "tX_test,null_variable=process_data(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125000, 407)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_to_exclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_predictions(tX,w):\n",
    "    prediction=tX.dot(w)\n",
    "    prediction[np.where(prediction <= 0)] = -1\n",
    "    prediction[np.where(prediction > 0)] = 1\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_prediction(prediction,y):\n",
    "    return (sum(y*prediction)/y.shape[0]+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(y,tX,w):\n",
    "    prediction=compute_predictions(tX,w)\n",
    "    return evaluate_prediction(prediction,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(y, tX, w):\n",
    "    \"\"\"Calculate the loss.\n",
    "\n",
    "    You can calculate the loss using mse or mae.\n",
    "    \"\"\"\n",
    "    error= y-tX.dot(w)\n",
    "    square=np.sum(error**2)/error.shape[0]\n",
    "    return square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-caee08f02ab0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcompute_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "def compute_gradient(y, tX, w):\n",
    "    \"\"\"Compute the gradient.\"\"\"\n",
    "    N=tX.shape[0]\n",
    "    error=y-tX.dot(w)\n",
    "    gradient=-1.0/N*(np.transpose(tX).dot(error))\n",
    "    return gradient\n",
    "        \n",
    "compute_gradient(y_train,tX_train,np.zeros([tX_train.shape[1]])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(y, tX, initial_w, max_iters, gamma): \n",
    "    \"\"\"Gradient descent algorithm.\"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # Compute gradient and loss\n",
    "        gradient=compute_gradient(y,tX,w)\n",
    "        loss=compute_loss(y,tX,w)\n",
    "        # Update w by gradient\n",
    "        w=w-gamma*gradient\n",
    "        # store w and loss\n",
    "        ws.append(np.copy(w))\n",
    "        losses.append(loss)\n",
    "        print(\"Gradient Descent({bi}/{ti}): loss={l}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss))\n",
    "\n",
    "    print(w.shape)\n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient for batch data.\"\"\"\n",
    "    N=tx.shape[0]\n",
    "    error=y-tx.dot(w)\n",
    "    gradient=-1.0/N*(np.transpose(tx).dot(error))\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_epochs, gamma):\n",
    "    \"\"\"Stochastic gradient descent algorithm.\"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    y_shuffle=[]\n",
    "    tx_shuffle=[]\n",
    "    for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "        y_shuffle.append(minibatch_y)\n",
    "        tx_shuffle.append(minibatch_tx)\n",
    "    for n_iter in range(max_epochs):\n",
    "        # compute stochastic gradient\n",
    "        gradient=compute_stoch_gradient(y_shuffle[n_iter],tx_shuffle[n_iter],w)\n",
    "        loss=compute_loss(y,tx,w)\n",
    "        # update w\n",
    "        w=w-gamma*gradient\n",
    "        # store w and loss\n",
    "        ws.append(np.copy(w))\n",
    "        losses.append(loss)\n",
    "        print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "\n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.00001\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.ones(tX.shape[1])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gradient_losses, w = gradient_descent(y, tX, w_initial, max_iters, gamma)\n",
    "#gradient_losses, w = stochastic_gradient_descent(y_train, tX_train, w_initial,30, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Gradient Descent: execution time={t:.3f} seconds\".format(t=exection_time))\n",
    "\n",
    "print(sum((y_test-tX_test.dot(w))**2)/tX_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.820448\n",
      "0.388704\n"
     ]
    }
   ],
   "source": [
    "def least_squares(y, tx):\n",
    "    \"\"\"calculate the least squares solution.\"\"\"\n",
    "    # returns mse, and optimal weights\n",
    "    \n",
    "    w=np.linalg.solve(tx.T.dot(tx),tx.T.dot(y))\n",
    "    mse=sum((y-tx.dot(w))**2)/tx.shape[0]\n",
    "    \n",
    "    return mse,w\n",
    "\n",
    "mse,w=least_squares(y,tX)\n",
    "print(evaluate(y,tX,w))\n",
    "print(evaluate(y_test,tX_test,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lamb):\n",
    "    \"\"\"implement ridge regression.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # ridge regression: TODO\n",
    "    # ***************************************************\n",
    "    w=np.linalg.solve(tx.T.dot(tx)+lamb**2*np.identity(tx.shape[1]),tx.T.dot(y))\n",
    "    #mse=sum((y-tx.dot(w))**2)/tx.shape[0]\n",
    "    return 1,w\n",
    "\n",
    "mse,w=ridge_regression(y,tX,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5c7ac8a278>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5cdac5a710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perc_tr=[]\n",
    "perc_te=[]\n",
    "\n",
    "lambdas = np.linspace(-0.001,0.001,101)\n",
    "for i,lamb in enumerate(lambdas):\n",
    "    mse,w=ridge_regression(y,tX,lamb)\n",
    "    \n",
    "    perc_tr.append(evaluate(y,tX,w))\n",
    "    perc_te.append(evaluate(y_test,tX_test,w))\n",
    "    \n",
    "    if i%10==0:\n",
    "        print(i)\n",
    "\n",
    "plt.plot(lambdas,perc_tr,label='train',color='r')\n",
    "plt.plot(lambdas,perc_te,label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659648\n",
      "0.381192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(407,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.amax(perc_te))\n",
    "print(np.median(perc_te))\n",
    "b=np.argmax(perc_te)\n",
    "best_lamb=lambdas[b]\n",
    "best_lamb\n",
    "mse,w=ridge_regression(y,tX,best_lamb)\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best so far\n",
    "- Degree 10 - 4 exp - all done, ridge regression: 0.82956\n",
    "- Degree 10 - 3 exp - all done, ridge regression: 0.829008\n",
    "- Degree 14 - 2 exp - all done, ridge regression: 0.82896\n",
    "- Degree 12 - 2 exp - all done, ridge regression: 0.828936\n",
    "- Degree 12 - all done, ridge regression: 0.828784\n",
    "- Degree 10 - 2 exp - all done, ridge regression: 0.828408\n",
    "- Degree 10 - exp - all done, ridge regression: 0.827816\n",
    "- Degree 10 - all done, ridge regression: 0.82717600000000002\n",
    "- Degree 6 - all done, ridge regression: 0.81543199999999993\n",
    "- Degree 8 - all done, ridge regression: 0.82291999999999998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Basic implementation of logistic regression using the least squares\n",
    "def logistic_regression(y,tx,tx_test,threshold=0.5):\n",
    "    mse,w=least_squares(y,tx)\n",
    "    \n",
    "    y_prev=tx.dot(w)\n",
    "    y_prev=1/(1+np.exp(-y_prev))\n",
    "    output_train=np.ones(y_prev.shape[0])\n",
    "    output_train[np.where(y_prev<threshold)] = -1\n",
    "    \n",
    "    y_test=tx_test.dot(w)\n",
    "    y_test=1/(1+np.exp(-y_test))\n",
    "    output_test=np.ones(y_test.shape[0])\n",
    "    output_test[np.where(y_test<threshold)] = -1\n",
    "    \n",
    "    return output_train,output_test\n",
    "\n",
    "thresholds=np.linspace(0.48,0.52,101)\n",
    "perc_log_tr=[]\n",
    "perc_log_te=[]\n",
    "for threshold in thresholds:\n",
    "    output_train,output_test=logistic_regression(y_train,tX_train,tX_test,threshold)\n",
    "    perc_log_tr.append(evaluate_prediction(output_train,y_train))\n",
    "    perc_log_te.append(evaluate_prediction(output_test,y_test))\n",
    "\n",
    "    \n",
    "plt.plot(thresholds,perc_log_tr,'r',label='Train')\n",
    "plt.plot(thresholds,perc_log_te,'b',label='Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tX_test_post=np.copy(tX_test)\n",
    "tX_test_post[tX_test_post==-999]=0\n",
    "prediction=compute_predictions(tX_test,w)\n",
    "evaluate_prediction(prediction,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum((y_test-tX_test.dot(w))**2)/tX_test.shape[0])\n",
    "print(tX_test.dot(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../../test.csv' # TODO: download train data and supply path here \n",
    "_, tX_final_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tX_final_test=build_poly(tX_final_test,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 29)\n"
     ]
    }
   ],
   "source": [
    "tX_final=process_data(tX_final_test,prod_to_exclude=prod_to_exclude,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 407)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_final[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1.  1. ..., -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = '../../predictions.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w, tX_final[0])\n",
    "#y_train,y_test = logistic_regression(y_train,tX_train,tX_final_test,0.48)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
